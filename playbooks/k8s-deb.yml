# Copyright 2025 s3rj1k
# SPDX-License-Identifier: MIT

# DEBUG: ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml
# ref: https://philprime.dev/guides/building-a-production-ready-kubernetes-cluster-from-scratch/lesson-8

---
- name: Kubernetes (k8s) on Debian AMD64
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  ignore_errors: false
  vars:
    KUBERNETES_VERSION: "v1.33"
    CRIO_VERSION: "v1.33"
    LB_IP_RANGE_START: ""
    LB_IP_RANGE_STOP: ""
    REGISTRY_MIRROR: ""
    WORKER_DATA: ""

  pre_tasks:
    - name: Check if system is supported
      block:
        - name: Check if distribution is Debian or Ubuntu
          fail:
            msg: "This playbook only supports Debian or Ubuntu distributions"
          when: ansible_distribution not in ["Debian", "Ubuntu"]

        - name: Check if architecture is AMD64
          fail:
            msg: "This playbook only supports AMD64 architecture"
          when: ansible_architecture != "x86_64"

        - name: Get OS version
          debug:
            msg: "Running on {{ ansible_distribution }} {{ ansible_distribution_version }} ({{ ansible_architecture }})"

    - name: Wait for system to be ready
      wait_for:
        path: /var/lib/cloud/instance/boot-finished
        timeout: 600
      when: ansible_service_mgr is defined and lookup('env', 'CLOUD_INIT') != ''

  handlers:
    - name: Restart sshd
      systemd:
        name: ssh
        state: restarted
        daemon_reload: yes
      when: ansible_service_mgr == 'systemd'

    - name: Restart crio
      systemd:
        name: crio
        state: restarted
        daemon_reload: yes
      when: ansible_service_mgr == 'systemd'

  tasks:
    - name: Clean up system packages and snap
      block:
        - name: Remove all snap packages
          shell: |
            snap list | awk '!/^Name|^core|^snapd|^lxd/ {print $1}' | xargs -r snap remove --purge
            snap list | awk '/^lxd/ {print $1}' | xargs -r snap remove --purge
            snap list | awk '/^core/ {print $1}' | xargs -r snap remove --purge
            snap list | awk '/^snapd/ {print $1}' | xargs -r snap remove --purge
            snap list | awk '!/^Name/ {print $1}' | xargs -r snap remove --purge
          ignore_errors: true
          when: ansible_distribution == "Ubuntu"

        - name: Remove system packages
          apt:
            name:
              - lxd
              - lxd-agent-loader
              - lxd-installer
              - plymouth
              - snapd
            state: absent
            purge: yes
            autoremove: yes

        - name: Remove snap directories
          file:
            path: "{{ item }}"
            state: absent
          loop:
            - /root/snap
            - /run/snapd
            - /snap
            - /var/cache/snapd
            - /var/snap

        - name: Mask unnecessary systemd units
          systemd:
            name: "{{ item }}"
            masked: yes
          loop:
            - lxd-installer.socket
            - plymouth-quit-wait.service
            - plymouth-quit.service
            - plymouth-read-write.service
            - plymouth-start.service
            - snapd.mounts-pre.target
            - snapd.seeded.service

    - name: Remove system users and groups
      block:
        - name: Remove users
          user:
            name: "{{ item }}"
            state: absent
            remove: yes
          loop:
            - lxd
          ignore_errors: true

        - name: Remove groups
          group:
            name: "{{ item }}"
            state: absent
          loop:
            - lxd
          ignore_errors: true

    - name: Update and upgrade system packages
      apt:
        update_cache: yes
        upgrade: yes
      register: system_upgraded

    - name: Consolidated package management
      # apt-cache madison $(apt-cache pkgnames)
      block:
        - name: Create directory for apt keyrings
          ansible.builtin.file:
            path: /etc/apt/keyrings
            state: directory
            mode: "0755"

        # Note: `ansible.builtin.deb822_repository` requires Ansible 2.15+

        - name: Download Kubernetes signing key
          ansible.builtin.get_url:
            url: "https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/{{ KUBERNETES_VERSION }}/deb/Release.key"
            dest: "/etc/apt/keyrings/kubernetes.asc"
            mode: "0644"

        - name: Create Kubernetes repository file
          ansible.builtin.copy:
            dest: "/etc/apt/sources.list.d/kubernetes.sources"
            content: |
              X-Repolib-Name: kubernetes
              Types: deb
              URIs: https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/{{ KUBERNETES_VERSION }}/deb/
              Signed-By: /etc/apt/keyrings/kubernetes.asc
              Suites: /
              Architectures: amd64
              Enabled: yes
            mode: "0644"

        - name: Download CRI-O signing key
          ansible.builtin.get_url:
            url: "https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/Release.key"
            dest: "/etc/apt/keyrings/crio.asc"
            mode: "0644"

        - name: Create CRI-O repository file
          ansible.builtin.copy:
            dest: "/etc/apt/sources.list.d/crio.sources"
            content: |
              X-Repolib-Name: crio
              Types: deb
              URIs: https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/
              Signed-By: /etc/apt/keyrings/crio.asc
              Suites: /
              Architectures: amd64
              Enabled: yes
            mode: "0644"

        - name: Update apt cache after adding repositories
          apt:
            update_cache: yes

        - name: Install remaining required packages
          apt:
            name:
              # Base dependencies
              - apt-transport-https
              - ca-certificates
              - curl
              - gettext-base
              - gnupg
              - tar
              # Locale
              - locales
              # SSH
              - openssh-server
              # GIT
              - git
              - git-lfs
              # Multipath
              - multipath-tools
              # Security
              - libseccomp2
              # Networking
              - ebtables
              - iproute2
              - libnetfilter-acct1
              - libnetfilter-cttimeout1
              - libnetfilter-log1
              - socat
              # Containers
              - buildah
              # Kubernetes
              - cri-o
              - kubeadm
              - kubectl
              - kubelet
              # Text and JSON processing
              - gawk
              - jq
              - nano
              - sed
              - yq
              # TUI
              - mc
            state: present
            update_cache: yes
          when: system_upgraded is success

    - name: Install clusterctl
      block:
        - name: Get latest version
          uri:
            url: "https://api.github.com/repos/kubernetes-sigs/cluster-api/releases/latest"
            return_content: yes
          register: release_info

        - name: Set version
          set_fact:
            # curl -s "https://api.github.com/repos/kubernetes-sigs/cluster-api/releases/latest" | jq -r ".tag_name"
            version: "{{ release_info.json.tag_name }}"
          when: release_info is defined and release_info.status == 200

        - name: Download and Install clusterctl binary ({{ version }})
          get_url:
            url: "https://github.com/kubernetes-sigs/cluster-api/releases/download/{{ version }}/clusterctl-linux-amd64"
            dest: /usr/local/bin/clusterctl
            mode: "0755"
          when: version | trim | length > 0
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Configure and generate locale
      block:
        - name: Set locale in configuration
          copy:
            dest: /etc/default/locale
            content: |
              LANG=C.UTF-8

        - name: Generate locale
          command: locale-gen en_US.UTF-8
          changed_when: false

    - name: Configure SSH client
      copy:
        dest: /etc/ssh/ssh_config
        content: |
          Host *
            AddressFamily inet
            ForwardAgent yes
            PasswordAuthentication no
            # CheckHostIP no
            # HashKnownHosts no
            # StrictHostKeyChecking no

    - name: Configure SSH server
      block:
        - name: Configure root login restrictions
          lineinfile:
            path: /etc/ssh/sshd_config
            regexp: "^#?PermitRootLogin"
            line: "PermitRootLogin prohibit-password"
          notify: Restart sshd

        - name: Remove cloud-init SSH configuration
          file:
            path: /etc/ssh/sshd_config.d/60-cloudimg-settings.conf
            state: absent
          notify: Restart sshd

    - name: Configure multipath
      block:
        - name: Create multipath configuration file
          copy:
            dest: /etc/multipath.conf
            content: |
              defaults {
                user_friendly_names yes
              }
            mode: "0644"
          register: multipath_conf

        - name: Enable and start multipathd service
          systemd:
            name: multipathd
            enabled: yes
            state: started

        - name: Restart multipathd service on configuration change
          systemd:
            name: multipathd
            state: restarted
          when: multipath_conf is changed

    - name: Configure kernel modules
      block:
        - name: Ensure required kernel modules are loaded
          shell: modprobe {{ item }}
          loop:
            - overlay
            - br_netfilter
          changed_when: false

        - name: Persist required kernel modules
          copy:
            dest: /etc/modules-load.d/99-local.conf
            content: |
              overlay
              br_netfilter
            mode: "0644"

        - name: Configure kernel parameters
          copy:
            dest: /etc/sysctl.d/99-local.conf
            content: |
              fs.inotify.max_user_instances = 8192
              fs.inotify.max_user_watches = 524288
              kernel.panic = 10
              kernel.panic_on_oops = 1
              net.bridge.bridge-nf-call-ip6tables = 1
              net.bridge.bridge-nf-call-iptables = 1
              net.ipv4.conf.all.rp_filter = 1
              net.ipv4.ip_forward = 1
              net.ipv4.tcp_congestion_control = bbr
              net.ipv6.conf.all.disable_ipv6 = 0
              net.ipv6.conf.all.forwarding = 1
              vm.overcommit_memory = 1
            mode: "0644"

        - name: Apply kernel parameters
          command: sysctl --system
          changed_when: false

    - name: Disable swap
      block:
        - name: Disable swap memory
          shell: |
            swapoff -a
          when: ansible_memory_mb.swap.total != 0

        - name: Disable swap entries in fstab
          lineinfile:
            path: /etc/fstab
            regexp: '^([^#].*\s+swap\s+.*)$'
            line: '#\1'
            backrefs: yes
          when: ansible_memory_mb.swap.total != 0

    - name: Configure GRUB
      block:
        - name: Create GRUB configuration directory
          file:
            path: /etc/default/grub.d
            state: directory
            mode: "0755"

        - name: Configure GRUB settings
          copy:
            dest: /etc/default/grub.d/50-settings.cfg
            content: |
              # Set the recordfail timeout
              GRUB_RECORDFAIL_TIMEOUT=0

              # Do not wait on grub prompt
              GRUB_TIMEOUT=0

              # Set the default commandline
              GRUB_CMDLINE_LINUX_DEFAULT="console=tty1 console=ttyS0 transparent_hugepage=madvise"

              # Set the grub console type
              GRUB_TERMINAL=console
            mode: "0644"
          register: grub_config

        - name: Check if /boot/grub directory exists
          stat:
            path: /boot/grub
          register: grub_dir

        - name: Update GRUB configuration
          command: update-grub
          when: grub_config is changed and grub_dir.stat.exists

    - name: Install etcd network tuning script and udev rule
      block:
        - name: Create directory for scripts
          file:
            path: /usr/local/sbin
            state: directory
            mode: "0755"
            owner: root
            group: root

        - name: Install etcd network tuning script
          copy:
            dest: /usr/local/sbin/etcd-network-tuning.sh
            content: |
              #!/bin/bash

              export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

              set -o errexit  # exits immediately on any unexpected error (does not bypass traps)
              set -o nounset  # will error if variables are used without first being defined
              set -o pipefail # any non-zero exit code in a piped command causes the pipeline to fail with that code

              trap on_exit ERR
              on_exit() {
                  echo "Error setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p emerg -t etcd-tuning
              }

              if [ "$#" -ne 1 ]; then
                  echo "Error: Usage: $0 <dev>" | systemd-cat -p emerg -t etcd-tuning
                  exit 1
              fi

              DEV=$1

              echo "Setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p info -t etcd-tuning
              tc qdisc del dev ${DEV} root 2>/dev/null || true
              tc qdisc add dev ${DEV} root handle 1: prio bands 3
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1

              exit 0
            mode: "0755"
            owner: root
            group: root
          register: script_install

        - name: Install udev rule for etcd network tuning
          copy:
            dest: /etc/udev/rules.d/90-etcd-network-tuning.rules
            content: |
              ACTION=="add", SUBSYSTEM=="net", SUBSYSTEMS=="pci|xen|vmbus" RUN+="/usr/local/sbin/etcd-network-tuning.sh $name"
            mode: "0644"
            owner: root
            group: root
          register: udev_rule_install

        - name: Reload udev rules if changed
          command: udevadm control --reload-rules
          when: udev_rule_install.changed

        - name: Trigger udev events for network interfaces if script or rules changed
          shell: find /sys/class/net -mindepth 1 -maxdepth 1 -type l -name "[a-z]*" -not -name "lo" -printf "%f\n" | xargs -I{} udevadm trigger --action=add --subsystem-match=net --sysname-match={}
          when: script_install.changed or udev_rule_install.changed
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Configure CRI-O
      # https://github.com/cri-o/cri-o/blob/main/README.md#configuration
      block:
        - name: Create CRI-O registries mirror configuration
          copy:
            dest: /etc/containers/registries.conf.d/mirror.conf
            content: |
              [[registry]]
              prefix = "docker.io"
              location = "docker.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "quay.io"
              location = "quay.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "gcr.io"
              location = "gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "registry.k8s.io"
              location = "registry.k8s.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "k8s.gcr.io"
              location = "k8s.gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]
            mode: "0644"
          when: REGISTRY_MIRROR is defined and REGISTRY_MIRROR | trim | length > 0
          notify: Restart crio

    - name: Initialize Kubernetes Control Plane
      block:
        - name: Extract latest patch release for {{ KUBERNETES_VERSION }}
          shell: |
            curl -s --fail "https://api.github.com/repos/kubernetes/kubernetes/releases" | tr -d '\000-\037' | jq -r '
              [.[] | select(.tag_name | startswith("{{ KUBERNETES_VERSION }}.")) |
               select(.prerelease == false)] |
              sort_by(.published_at) |
              reverse'
          register: k8s_releases_filtered_raw

        - name: Parse filtered releases
          set_fact:
            k8s_releases_filtered: "{{ k8s_releases_filtered_raw.stdout | from_json }}"
          when:
            - k8s_releases_filtered_raw is defined
            - k8s_releases_filtered_raw.stdout != ""
            - k8s_releases_filtered_raw.stdout != "null"

        - name: Set version from patch releases if available
          set_fact:
            version: "{{ k8s_releases_filtered[0].tag_name }}"
          when:
            - k8s_releases_filtered is defined
            - k8s_releases_filtered | trim | length > 0

        - name: Use KUBERNETES_VERSION as fallback if no patch releases found
          set_fact:
            version: "{{ KUBERNETES_VERSION }}"
          when:
            - k8s_releases_filtered is defined
            - k8s_releases_filtered | trim | length == 0

        - name: Create kubeadm configuration directory
          file:
            path: /etc/kubeadm
            state: directory
            mode: "0755"

        - name: Create kubeadm configuration file
          # FeatureGates:
          #  - https://kubernetes.io/docs/tasks/configure-pod-container/image-volumes/
          copy:
            dest: /etc/kubeadm/init.yaml
            content: |
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: InitConfiguration
              nodeRegistration:
                criSocket: "unix:///var/run/crio/crio.sock"
              skipPhases:
                - addon/kube-proxy
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: ClusterConfiguration
              kubernetesVersion: {{ version }}
              ---
              apiVersion: kubelet.config.k8s.io/v1beta1
              kind: KubeletConfiguration
              cgroupDriver: systemd
              featureGates:
                ImageVolume: true
            mode: "0644"
          when: version is defined and version | trim | length > 0

        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Check if Kubernetes cluster is already running
          command: kubectl get nodes
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubectl_get_nodes
          changed_when: false
          failed_when: false

        - name: Reset Kubernetes Control Plane if needed
          command: kubeadm reset --force
          register: kubeadm_reset
          changed_when: true
          failed_when: false
          when: kubectl_get_nodes.rc != 0

        - name: Initialize the Kubernetes Control Plane
          command: kubeadm init --config=/etc/kubeadm/init.yaml
          args:
            creates: /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubeadm_init
          changed_when: true
          failed_when: kubeadm_init.rc != 0
          when: kubectl_get_nodes.rc != 0

        - name: Create .kube directory for root user
          file:
            path: /root/.kube
            state: directory
            owner: root
            group: root
            mode: "0700"

        - name: Create symlink from admin.conf to .kube/config
          file:
            src: /etc/kubernetes/admin.conf
            dest: /root/.kube/config
            state: link
            force: true

        - name: Check if Control Plane taint exists
          shell: kubectl --kubeconfig /etc/kubernetes/admin.conf get nodes -o jsonpath='{.items[*].spec.taints[?(@.key=="node-role.kubernetes.io/control-plane")].key}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: taint_check
          changed_when: false

        - name: Remove taints from Control Plane nodes
          command: kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/control-plane-
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: remove_taint
          changed_when: remove_taint.rc == 0
          failed_when: false
          when: taint_check.stdout | length > 0
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    # Install Cilium as CNI (https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/)
    - name: Install Cilium CNI
      block:
        - name: Fetch Cilium CLI stable version
          uri:
            url: "https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt"
            return_content: yes
          register: cilium_cli_stable

        - name: Set Cilium CLI version
          set_fact:
            cilium_cli_version: "{{ cilium_cli_stable.content | trim }}"
          when: cilium_cli_stable is defined and cilium_cli_stable.status == 200

        - name: Fetch Cilium stable version
          uri:
            url: "https://raw.githubusercontent.com/cilium/cilium/main/stable.txt"
            return_content: yes
          register: cilium_stable

        - name: Set Cilium version
          set_fact:
            cilium_version: "{{ cilium_stable.content | trim }}"
          when: cilium_stable is defined and cilium_stable.status == 200

        - name: Download and install Cilium CLI {{ cilium_cli_version }}
          shell: |
            curl -L --fail https://github.com/cilium/cilium-cli/releases/download/{{ cilium_cli_version }}/cilium-linux-amd64.tar.gz | \
            tar xzf - -C /usr/local/bin
          args:
            creates: /usr/local/bin/cilium
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Make Cilium CLI executable
          file:
            path: /usr/local/bin/cilium
            mode: "0755"
            state: file
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Check if Cilium is already installed
          command: cilium status --kubeconfig /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_status
          changed_when: false
          failed_when: false
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Install Cilium {{ cilium_version }} if not already installed
          command: cilium install --version {{ cilium_version }} --kubeconfig /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_install
          changed_when: cilium_install.rc == 0
          failed_when: cilium_install.rc != 0
          when:
            - cilium_status.rc != 0
            - cilium_version is defined and cilium_version | trim | length > 0

        - name: Wait for Cilium to be ready
          command: cilium status --wait --kubeconfig /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_wait
          changed_when: false
          until: cilium_wait.rc == 0
          retries: 5
          delay: 30
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Configure LB
      block:
        - name: Create CiliumLoadBalancerIPPool
          copy:
            dest: /root/lb-config.yaml
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumLoadBalancerIPPool
              metadata:
                name: default-pool
              spec:
                blocks:
                  - start: "{{ LB_IP_RANGE_START }}"
                    stop: "{{ LB_IP_RANGE_STOP }}"
            mode: "0644"

        - name: Apply CiliumLoadBalancerIPPool configuration
          command: kubectl apply -f /root/lb-config.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_result
          until: apply_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - LB_IP_RANGE_START | default("") | length > 0
        - LB_IP_RANGE_STOP | default("") | length > 0

    - name: Configure Local Path Provisioner
      block:
        - name: Get latest version
          uri:
            url: "https://api.github.com/repos/rancher/local-path-provisioner/releases/latest"
            return_content: yes
          register: release_info

        - name: Set version
          set_fact:
            # curl -s "https://api.github.com/repos/rancher/local-path-provisioner/releases/latest" | jq -r ".tag_name"
            version: "{{ release_info.json.tag_name }}"
          when: release_info is defined and release_info.status == 200

        - name: Apply Local Path Provisioner manifest ({{ version }})
          command: kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/{{ version }}/deploy/local-path-storage.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_result
          until: apply_result.rc == 0
          retries: 5
          delay: 30

        - name: Set Local Path Storage as default storage class
          shell: |
            kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: default_sc_result
          until: default_sc_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Initialize Kubernetes Worker Node
      block:
        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Join the Kubernetes cluster as worker node
          command: "{{ WORKER_DATA }}"
          register: worker_join
          changed_when: true
          failed_when: worker_join.rc != 0
          until: worker_join is succeeded
          retries: 5
          delay: 30
      when: WORKER_DATA is defined and WORKER_DATA | trim | length > 0

    - name: Mask unnecessary systemd units
      systemd:
        name: "{{ item }}"
        masked: yes
      loop:
        - display-manager.service

    - name: Handle system reboot check
      block:
        - name: Check if reboot is required
          stat:
            path: /var/run/reboot-required
          register: reboot_required_file

        - name: Print reboot status
          debug:
            msg: "System reboot is required"
          when: reboot_required_file.stat.exists
      when: system_upgraded is success
