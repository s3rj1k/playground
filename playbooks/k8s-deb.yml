# Copyright 2025 s3rj1k
# SPDX-License-Identifier: MIT

# ref: https://philprime.dev/guides/building-a-production-ready-kubernetes-cluster-from-scratch/lesson-8
# ref: https://littlechimera.com/posts/cilium-lb-cp-endpoint/
#
# DEBUG: ansible-playbook playbooks/k8s-deb.yml (for local files)
#
# Single control plane node:
#   ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml
#
# Custom pod/service CIDRs:
#   ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml \
#     -e CLUSTER_CIDR=172.20.0.0/16 -e SERVICE_CIDR=172.21.0.0/16
#
# HA control plane with Cilium L2 LoadBalancer:
#   # First CP node:
#   ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml -e CP_LB_IP=192.168.42.42
#
#   # Generate join command on first CP node:
#   kubeadm token create --print-join-command --certificate-key $(kubeadm init phase upload-certs --upload-certs | tail -1)
#
#   # Additional CP nodes (use JSON format for ansible -e with values containing spaces):
#   ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml \
#     -e CP_LB_IP=192.168.42.42 \
#     -e '{"CP_JOIN_DATA": "kubeadm join <CP_LB_IP>.nip.io:6443 --token <token> --discovery-token-ca-cert-hash <hash> --control-plane --certificate-key <key>"}'
#
# Worker nodes:
#   # Generate join command on any CP node:
#   kubeadm token create --print-join-command
#
#   # Join worker (use JSON format for ansible -e with values containing spaces):
#   # NOTE: For HA setups, use <CP_LB_IP>.nip.io:6443 (not raw IP)
#   ansible-pull -U https://github.com/s3rj1k/playground.git playbooks/k8s-deb.yml \
#     -e '{"WORKER_DATA": "kubeadm join <CP_LB_IP>.nip.io:6443 --token <token> --discovery-token-ca-cert-hash <hash>"}'
#
# Find which node holds the Cilium L2 VIP:
#   kubectl get lease cilium-l2announce-kube-system-kubernetes-external -n kube-system -o jsonpath='{.spec.holderIdentity}{"\n"}'

---
- name: Kubernetes (k8s) on Debian/Ubuntu AMD64
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  ignore_errors: false
  vars:
    KUBERNETES_VERSION: "v1.34"
    CRIO_VERSION: "v1.34"
    CLUSTER_CIDR: "10.244.0.0/16"
    SERVICE_CIDR: "10.96.0.0/16"
    LB_IP_RANGE_START: ""
    LB_IP_RANGE_STOP: ""
    CP_LB_IP: ""
    CP_JOIN_DATA: ""
    REGISTRY_MIRROR: ""
    WORKER_DATA: ""
    MANIFESTS_DIR: "/etc/kubernetes/manifests.d"
    ENABLE_FLUX_CD: true
    CILIUM_LB_ENABLED: true
    CILIUM_DEVICES: "ens+ eth+ virbr+"

  pre_tasks:
    - name: Check if system is supported
      block:
        - name: Check if distribution is Debian or Ubuntu
          fail:
            msg: "This playbook only supports Debian or Ubuntu distributions"
          when: ansible_distribution not in ["Debian", "Ubuntu"]

        - name: Check if architecture is AMD64
          fail:
            msg: "This playbook only supports AMD64 architecture"
          when: ansible_architecture != "x86_64"

        - name: Get OS version
          debug:
            msg: "Running on {{ ansible_distribution }} {{ ansible_distribution_version }} ({{ ansible_architecture }})"

        - name: Check for conflicting join data
          fail:
            msg: "Cannot specify both CP_JOIN_DATA and WORKER_DATA. Use only one."
          when:
            - CP_JOIN_DATA is defined and CP_JOIN_DATA | trim | length > 0
            - WORKER_DATA is defined and WORKER_DATA | trim | length > 0

    - name: Wait for system to be ready
      wait_for:
        path: /var/lib/cloud/instance/boot-finished
        timeout: 600
      when: ansible_service_mgr is defined and lookup('env', 'CLOUD_INIT') != ''

  handlers:
    - name: Restart crio
      systemd:
        name: crio
        state: restarted
        daemon_reload: yes
      when: ansible_service_mgr == 'systemd'

  tasks:
    - name: Update and upgrade system packages
      apt:
        update_cache: yes
        upgrade: yes
      register: system_upgraded

    - name: Consolidated package management
      # apt-cache madison $(apt-cache pkgnames)
      block:
        - name: Create directory for apt keyrings
          ansible.builtin.file:
            path: /etc/apt/keyrings
            state: directory
            mode: "0755"

        # Note: `ansible.builtin.deb822_repository` requires Ansible 2.15+

        - name: Download Kubernetes signing key
          ansible.builtin.get_url:
            url: "https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/{{ KUBERNETES_VERSION }}/deb/Release.key"
            dest: "/etc/apt/keyrings/kubernetes.asc"
            mode: "0644"

        - name: Create Kubernetes repository file
          ansible.builtin.copy:
            dest: "/etc/apt/sources.list.d/kubernetes.sources"
            content: |
              X-Repolib-Name: kubernetes
              Types: deb
              URIs: https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/{{ KUBERNETES_VERSION }}/deb/
              Signed-By: /etc/apt/keyrings/kubernetes.asc
              Suites: /
              Architectures: amd64
              Enabled: yes
            mode: "0644"

        - name: Download CRI-O signing key
          ansible.builtin.get_url:
            url: "https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/Release.key"
            dest: "/etc/apt/keyrings/crio.asc"
            mode: "0644"

        - name: Create CRI-O repository file
          ansible.builtin.copy:
            dest: "/etc/apt/sources.list.d/crio.sources"
            content: |
              X-Repolib-Name: crio
              Types: deb
              URIs: https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/
              Signed-By: /etc/apt/keyrings/crio.asc
              Suites: /
              Architectures: amd64
              Enabled: yes
            mode: "0644"

        - name: Update apt cache after adding repositories
          apt:
            update_cache: yes

        - name: Install remaining required packages
          apt:
            name:
              # Base dependencies
              - apt-transport-https
              - ca-certificates
              - curl
              - gettext-base
              - gnupg
              - tar
              # Multipath
              - multipath-tools
              # Security
              - libseccomp2
              # Networking
              - ebtables
              - iproute2
              - libnetfilter-acct1
              - libnetfilter-cttimeout1
              - libnetfilter-log1
              - socat
              # Kubernetes
              - cri-o
              - kubeadm
              - kubectl
              - kubelet
              # Text and JSON processing
              - gawk
              - jq
              - sed
            state: present
            update_cache: yes
          when: system_upgraded is success

    - name: Configure multipath
      block:
        - name: Create multipath configuration file
          copy:
            dest: /etc/multipath.conf
            content: |
              defaults {
                user_friendly_names yes
              }
            mode: "0644"
          register: multipath_conf

        - name: Enable and start multipathd service
          systemd:
            name: multipathd
            enabled: yes
            state: started

        - name: Restart multipathd service on configuration change
          systemd:
            name: multipathd
            state: restarted
          when: multipath_conf is changed

    - name: Configure kernel modules
      block:
        - name: Ensure required kernel modules are loaded
          shell: modprobe {{ item }}
          loop:
            - overlay
            - br_netfilter
          changed_when: false

        - name: Persist required kernel modules
          copy:
            dest: /etc/modules-load.d/95-local.conf
            content: |
              overlay
              br_netfilter
            mode: "0644"

        - name: Configure kernel parameters
          copy:
            dest: /etc/sysctl.d/95-local.conf
            content: |
              fs.inotify.max_user_instances = 8192
              fs.inotify.max_user_watches = 524288
              kernel.panic = 10
              kernel.panic_on_oops = 1
              net.bridge.bridge-nf-call-ip6tables = 1
              net.bridge.bridge-nf-call-iptables = 1
              net.ipv4.conf.all.rp_filter = 1
              net.ipv4.ip_forward = 1
              net.ipv4.tcp_congestion_control = bbr
              net.ipv6.conf.all.disable_ipv6 = 0
              net.ipv6.conf.all.forwarding = 1
              vm.overcommit_memory = 1
            mode: "0644"

        - name: Apply kernel parameters
          command: sysctl --system
          changed_when: false

    - name: Disable swap
      block:
        - name: Disable swap memory
          shell: |
            swapoff -a
          when: ansible_memory_mb.swap.total != 0

        - name: Disable swap entries in fstab
          lineinfile:
            path: /etc/fstab
            regexp: '^([^#].*\s+swap\s+.*)$'
            line: '#\1'
            backrefs: yes
          when: ansible_memory_mb.swap.total != 0

    - name: Configure GRUB
      block:
        - name: Create GRUB configuration directory
          file:
            path: /etc/default/grub.d
            state: directory
            mode: "0755"

        - name: Configure GRUB settings
          copy:
            dest: /etc/default/grub.d/50-settings.cfg
            content: |
              # Set the recordfail timeout
              GRUB_RECORDFAIL_TIMEOUT=0

              # Do not wait on grub prompt
              GRUB_TIMEOUT=0

              # Set the default commandline
              GRUB_CMDLINE_LINUX_DEFAULT="console=tty1 console=ttyS0 transparent_hugepage=madvise"

              # Set the grub console type
              GRUB_TERMINAL=console
            mode: "0644"
          register: grub_config

        - name: Check if /boot/grub directory exists
          stat:
            path: /boot/grub
          register: grub_dir

        - name: Update GRUB configuration
          command: update-grub
          when: grub_config is changed and grub_dir.stat.exists

    - name: Install etcd network tuning script and udev rule
      block:
        - name: Create directory for scripts
          file:
            path: /usr/local/sbin
            state: directory
            mode: "0755"
            owner: root
            group: root

        - name: Install etcd network tuning script
          copy:
            dest: /usr/local/sbin/etcd-network-tuning.sh
            content: |
              #!/bin/bash

              export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

              set -o errexit  # exits immediately on any unexpected error (does not bypass traps)
              set -o nounset  # will error if variables are used without first being defined
              set -o pipefail # any non-zero exit code in a piped command causes the pipeline to fail with that code

              trap on_exit ERR
              on_exit() {
                  echo "Error setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p emerg -t etcd-tuning
              }

              if [ "$#" -ne 1 ]; then
                  echo "Error: Usage: $0 <dev>" | systemd-cat -p emerg -t etcd-tuning
                  exit 1
              fi

              DEV=$1

              echo "Setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p info -t etcd-tuning
              tc qdisc del dev ${DEV} root 2>/dev/null || true
              tc qdisc add dev ${DEV} root handle 1: prio bands 3
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1

              exit 0
            mode: "0755"
            owner: root
            group: root
          register: script_install

        - name: Install udev rule for etcd network tuning
          copy:
            dest: /etc/udev/rules.d/90-etcd-network-tuning.rules
            content: |
              ACTION=="add", SUBSYSTEM=="net", SUBSYSTEMS=="pci|xen|vmbus" RUN+="/usr/local/sbin/etcd-network-tuning.sh $name"
            mode: "0644"
            owner: root
            group: root
          register: udev_rule_install

        - name: Reload udev rules if changed
          command: udevadm control --reload-rules
          when: udev_rule_install.changed

        - name: Trigger udev events for network interfaces if script or rules changed
          shell: find /sys/class/net -mindepth 1 -maxdepth 1 -type l -name "[a-z]*" -not -name "lo" -printf "%f\n" | xargs -I{} udevadm trigger --action=add --subsystem-match=net --sysname-match={}
          when: script_install.changed or udev_rule_install.changed
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Configure CRI-O
      # https://github.com/cri-o/cri-o/blob/main/README.md#configuration
      block:
        - name: Disable short name mode enforcement in CRI-O
          copy:
            dest: /etc/crio/crio.conf.d/20-shortnames.conf
            content: |
              [crio.image]
              short_name_mode = "disabled"
            mode: "0644"
          notify: Restart crio

        - name: Create CRI-O registries mirror configuration
          copy:
            dest: /etc/containers/registries.conf.d/mirror.conf
            content: |
              [[registry]]
              prefix = "docker.io"
              location = "docker.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "quay.io"
              location = "quay.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "gcr.io"
              location = "gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "registry.k8s.io"
              location = "registry.k8s.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "k8s.gcr.io"
              location = "k8s.gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]
            mode: "0644"
          when: REGISTRY_MIRROR is defined and REGISTRY_MIRROR | trim | length > 0
          notify: Restart crio

    - name: Prepare Control Plane Node
      block:
        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Extract latest patch release for {{ KUBERNETES_VERSION }}
          shell: |
            curl -s --fail "https://api.github.com/repos/kubernetes/kubernetes/releases" | tr -d '\000-\037' | jq -r '
              [.[] | select(.tag_name | startswith("{{ KUBERNETES_VERSION }}.")) |
               select(.prerelease == false)] |
              sort_by(.published_at) |
              reverse'
          register: k8s_releases_filtered_raw

        - name: Parse filtered releases
          set_fact:
            k8s_releases_filtered: "{{ k8s_releases_filtered_raw.stdout | from_json }}"
          when:
            - k8s_releases_filtered_raw is defined
            - k8s_releases_filtered_raw.stdout != ""
            - k8s_releases_filtered_raw.stdout != "null"

        - name: Set version from patch releases if available
          set_fact:
            version: "{{ k8s_releases_filtered[0].tag_name }}"
          when:
            - k8s_releases_filtered is defined
            - k8s_releases_filtered | trim | length > 0

        - name: Use KUBERNETES_VERSION as fallback if no patch releases found
          set_fact:
            version: "{{ KUBERNETES_VERSION }}"
          when:
            - k8s_releases_filtered is defined
            - k8s_releases_filtered | trim | length == 0

        - name: Check if Kubernetes cluster is already running
          command: kubectl get nodes
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubectl_get_nodes
          changed_when: false
          failed_when: false

        - name: Reset Kubernetes Control Plane if needed
          command: kubeadm reset --force
          register: kubeadm_reset
          changed_when: true
          failed_when: false
          when: kubectl_get_nodes.rc != 0
      when: WORKER_DATA is not defined or WORKER_DATA | trim | length == 0

    - name: Initialize First Control Plane Node
      block:
        - name: Create manifests directory
          file:
            path: "{{ MANIFESTS_DIR }}"
            state: directory
            mode: "0755"

        - name: Create kubeadm configuration directory
          file:
            path: /etc/kubeadm
            state: directory
            mode: "0755"

        - name: Create kubeadm configuration file
          # FeatureGates:
          #  - https://kubernetes.io/docs/tasks/configure-pod-container/image-volumes/
          copy:
            dest: /etc/kubeadm/init.yaml
            content: |
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: InitConfiguration
              nodeRegistration:
                criSocket: "unix:///var/run/crio/crio.sock"
              skipPhases:
                - addon/kube-proxy
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: ClusterConfiguration
              kubernetesVersion: {{ version }}
              {% if CP_LB_IP is defined and CP_LB_IP | trim | length > 0 %}
              controlPlaneEndpoint: "{{ CP_LB_IP }}.nip.io:6443"
              {% endif %}
              networking:
                podSubnet: "{{ CLUSTER_CIDR }}"
                serviceSubnet: "{{ SERVICE_CIDR }}"
              ---
              apiVersion: kubelet.config.k8s.io/v1beta1
              kind: KubeletConfiguration
              cgroupDriver: systemd
              featureGates:
                ImageVolume: true
            mode: "0644"
          when: version is defined and version | trim | length > 0

        - name: Add control plane endpoint to /etc/hosts for localhost access
          lineinfile:
            path: /etc/hosts
            line: "127.0.0.1 {{ CP_LB_IP }}.nip.io"
            state: present
          when: CP_LB_IP is defined and CP_LB_IP | trim | length > 0

        - name: Initialize the Kubernetes Control Plane
          command: kubeadm init --config=/etc/kubeadm/init.yaml
          args:
            creates: /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubeadm_init
          changed_when: true
          failed_when: kubeadm_init.rc != 0
          when: kubectl_get_nodes.rc != 0

        - name: Check if Control Plane taint exists
          shell: kubectl --kubeconfig /etc/kubernetes/admin.conf get nodes -o jsonpath='{.items[*].spec.taints[?(@.key=="node-role.kubernetes.io/control-plane")].key}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: taint_check
          changed_when: false

        - name: Remove taints from Control Plane nodes
          command: kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/control-plane-
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: remove_taint
          changed_when: remove_taint.rc == 0
          failed_when: false
          when: taint_check.stdout | length > 0

        - name: Create .kube directory
          file:
            path: /root/.kube
            state: directory
            mode: "0755"

        - name: Copy kubeconfig to .kube/config
          copy:
            src: /etc/kubernetes/admin.conf
            dest: /root/.kube/config
            remote_src: true
            mode: "0600"
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0

    # Install Cilium as CNI (https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/)
    - name: Install Cilium CNI
      block:
        - name: Fetch Cilium CLI stable version
          uri:
            url: "https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt"
            return_content: yes
          register: cilium_cli_stable

        - name: Set Cilium CLI version
          set_fact:
            cilium_cli_version: "{{ cilium_cli_stable.content | trim }}"
          when: cilium_cli_stable is defined and cilium_cli_stable.status == 200

        - name: Fetch Cilium stable version
          uri:
            url: "https://raw.githubusercontent.com/cilium/cilium/main/stable.txt"
            return_content: yes
          register: cilium_stable

        - name: Set Cilium version
          set_fact:
            cilium_version: "{{ cilium_stable.content | trim }}"
          when: cilium_stable is defined and cilium_stable.status == 200

        - name: Download and install Cilium CLI {{ cilium_cli_version | default('') }}
          shell: |
            curl -L --fail https://github.com/cilium/cilium-cli/releases/download/{{ cilium_cli_version }}/cilium-linux-amd64.tar.gz | \
            tar xzf - -C /usr/local/bin
          args:
            creates: /usr/local/bin/cilium
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Make Cilium CLI executable
          file:
            path: /usr/local/bin/cilium
            mode: "0755"
            state: file
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Check if Cilium is already installed
          command: cilium status --kubeconfig /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_status
          changed_when: false
          failed_when: false
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0

        - name: Install Cilium {{ cilium_version | default('') }} if not already installed
          command: >
            cilium install
            --version {{ cilium_version }}
            --kubeconfig /etc/kubernetes/admin.conf
            {% if CILIUM_LB_ENABLED | bool %}
            --set kubeProxyReplacement=true
            --set l2announcements.enabled=true
            --set lbIPAM.defaultServiceIPAM=none
            --set bpf-lb-sock-hostns-only=true
            {% endif %}
            --set k8sClientRateLimit.qps=10
            --set k8sClientRateLimit.burst=30
            --set devices='{{ CILIUM_DEVICES }}'
            --set ipam.operator.clusterPoolIPv4PodCIDRList={{ CLUSTER_CIDR }}
            {% if CP_LB_IP is defined and CP_LB_IP | trim | length > 0 %}
            --set k8sServiceHost={{ CP_LB_IP }}.nip.io
            --set k8sServicePort=6443
            {% endif %}
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_install
          changed_when: cilium_install.rc == 0
          failed_when: cilium_install.rc != 0
          when:
            - cilium_status.rc != 0
            - cilium_version is defined and cilium_version | trim | length > 0

        - name: Wait for Cilium to be ready
          command: cilium status --wait --kubeconfig /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_wait
          changed_when: false
          until: cilium_wait.rc == 0
          retries: 5
          delay: 30
          when: cilium_cli_version is defined and cilium_cli_version | trim | length > 0
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0

    - name: Configure LB
      block:
        - name: Create CiliumLoadBalancerIPPool
          copy:
            dest: "{{ MANIFESTS_DIR }}/cilium-lb-pool.yaml"
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumLoadBalancerIPPool
              metadata:
                name: default-pool
              spec:
                blocks:
                  - start: "{{ LB_IP_RANGE_START }}"
                    stop: "{{ LB_IP_RANGE_STOP }}"
            mode: "0644"

        - name: Apply CiliumLoadBalancerIPPool configuration
          command: kubectl apply -f {{ MANIFESTS_DIR }}/cilium-lb-pool.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_result
          until: apply_result.rc == 0
          retries: 5
          delay: 30

        - name: Create CiliumL2AnnouncementPolicy for default pool
          copy:
            dest: "{{ MANIFESTS_DIR }}/cilium-l2-policy.yaml"
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumL2AnnouncementPolicy
              metadata:
                name: default
              spec:
                interfaces:
                  - ^eno[0-9]+
                  - ^enp[0-9]+
                  - ^ens[0-9]+
                  - ^eth[0-9]+
                  - ^virbr[0-9]+
                loadBalancerIPs: true
            mode: "0644"

        - name: Apply CiliumL2AnnouncementPolicy for default pool
          command: kubectl apply -f {{ MANIFESTS_DIR }}/cilium-l2-policy.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_l2_result
          until: apply_l2_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0
        - CILIUM_LB_ENABLED | bool
        - LB_IP_RANGE_START | default("") | length > 0
        - LB_IP_RANGE_STOP | default("") | length > 0

    - name: Configure Control Plane LoadBalancer Endpoint
      block:
        - name: Create CiliumLoadBalancerIPPool for API server
          copy:
            dest: "{{ MANIFESTS_DIR }}/cilium-cp-lb-pool.yaml"
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumLoadBalancerIPPool
              metadata:
                name: api-server-pool
              spec:
                blocks:
                  - cidr: "{{ CP_LB_IP }}/32"
            mode: "0644"

        - name: Apply CiliumLoadBalancerIPPool for API server
          command: kubectl apply -f {{ MANIFESTS_DIR }}/cilium-cp-lb-pool.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_pool_result
          until: apply_pool_result.rc == 0
          retries: 5
          delay: 30

        - name: Create CiliumL2AnnouncementPolicy for control plane
          copy:
            dest: "{{ MANIFESTS_DIR }}/cilium-cp-l2-policy.yaml"
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumL2AnnouncementPolicy
              metadata:
                name: control-plane
              spec:
                serviceSelector:
                  matchLabels:
                    component: apiserver
                    provider: kubernetes
                nodeSelector:
                  matchExpressions:
                    - key: node-role.kubernetes.io/control-plane
                      operator: Exists
                interfaces:
                  - ^eno[0-9]+
                  - ^enp[0-9]+
                  - ^ens[0-9]+
                  - ^eth[0-9]+
                  - ^virbr[0-9]+
                loadBalancerIPs: true
            mode: "0644"

        - name: Apply CiliumL2AnnouncementPolicy for control plane
          command: kubectl apply -f {{ MANIFESTS_DIR }}/cilium-cp-l2-policy.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_policy_result
          until: apply_policy_result.rc == 0
          retries: 5
          delay: 30

        - name: Create kubernetes-external LoadBalancer Service
          copy:
            dest: "{{ MANIFESTS_DIR }}/cilium-cp-lb-service.yaml"
            content: |
              apiVersion: v1
              kind: Service
              metadata:
                annotations:
                  io.cilium/lb-ipam-ips: "{{ CP_LB_IP }}"
                labels:
                  component: apiserver
                  provider: kubernetes
                name: kubernetes-external
                namespace: kube-system
              spec:
                selector:
                  component: kube-apiserver
                  tier: control-plane
                ports:
                  - name: https
                    port: 6443
                    protocol: TCP
                    targetPort: 6443
                type: LoadBalancer
            mode: "0644"

        - name: Apply kubernetes-external LoadBalancer Service
          command: kubectl apply -f {{ MANIFESTS_DIR }}/cilium-cp-lb-service.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_service_result
          until: apply_service_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0
        - CILIUM_LB_ENABLED | bool
        - CP_LB_IP is defined and CP_LB_IP | trim | length > 0

    - name: Configure Addon Manager
      # ref: https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/addon-manager/README.md
      # ref: https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/manifests/kube-addon-manager.yaml
      block:
        - name: Create addons directory
          file:
            path: /etc/kubernetes/addons
            state: directory
            mode: "0755"
            owner: root
            group: root

        - name: Download kube-addon-manager manifest
          ansible.builtin.get_url:
            url: "https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/gce/manifests/kube-addon-manager.yaml"
            dest: /etc/kubernetes/manifests/kube-addon-manager.yaml
            mode: "0644"

        - name: Configure addon-manager runAsUser
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '\{\{runAsUser\}\}'
            replace: '0'

        - name: Configure addon-manager runAsGroup
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '\{\{runAsGroup\}\}'
            replace: '0'

        - name: Configure addon-manager kubectl_prune_whitelist_override
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '\{\{kubectl_prune_whitelist_override\}\}'
            replace: ''

        - name: Configure addon-manager kubectl_extra_prune_whitelist
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '\{\{kubectl_extra_prune_whitelist\}\}'
            replace: ''

        - name: Update KUBECTL_OPTS to use admin.conf
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '--kubeconfig=/etc/srv/kubernetes/addon-manager/kubeconfig'
            replace: '--kubeconfig=/etc/kubernetes/admin.conf'

        - name: Remove srvkube volume mount
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '^\s*- mountPath: /etc/srv/kubernetes/addon-manager/\n\s*name: srvkube\n\s*readOnly: true\n'
            replace: ''

        - name: Remove srvkube volume
          ansible.builtin.replace:
            path: /etc/kubernetes/manifests/kube-addon-manager.yaml
            regexp: '^\s*- hostPath:\n\s*path: /etc/srv/kubernetes/addon-manager/\n\s*name: srvkube\n'
            replace: ''

        - name: Wait for addon-manager pod to be running
          shell: |
            kubectl get pod kube-addon-manager-{{ ansible_hostname }} -n kube-system -o jsonpath='{.status.phase}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: addon_manager_status
          changed_when: false
          until: addon_manager_status.stdout == "Running"
          retries: 30
          delay: 10
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0

    - name: Configure Flux CD
      block:
        - name: Download Flux CD manifest
          ansible.builtin.get_url:
            url: "https://github.com/fluxcd/flux2/releases/latest/download/install.yaml"
            dest: /etc/kubernetes/addons/flux-cd.yaml
            mode: "0644"

        # https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/addon-manager/README.md
        # EnsureExists: Addon will only be created if it doesn't exist, users can modify it
        # Reconcile: Addon will be periodically reconciled to match the manifest
        - name: Add addon-manager label to Flux CD manifest
          ansible.builtin.shell: |
            sed -i '/^  labels:$/a\    addonmanager.kubernetes.io/mode: EnsureExists' /etc/kubernetes/addons/flux-cd.yaml
          args:
            executable: /bin/bash
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0
        - ENABLE_FLUX_CD | default(true) | bool

    - name: Cleanup /etc/hosts bootstrap hack
      block:
        - name: Wait for Cilium LB to assign external IP
          shell: |
            kubectl get svc kubernetes-external -n kube-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: lb_ip
          changed_when: false
          until: lb_ip.stdout == CP_LB_IP
          retries: 30
          delay: 10

        - name: Remove /etc/hosts bootstrap hack after Cilium LB is ready
          lineinfile:
            path: /etc/hosts
            line: "127.0.0.1 {{ CP_LB_IP }}.nip.io"
            state: absent
      when:
        - WORKER_DATA is not defined or WORKER_DATA | trim | length == 0
        - CP_JOIN_DATA is not defined or CP_JOIN_DATA | trim | length == 0
        - CP_LB_IP is defined and CP_LB_IP | trim | length > 0

    - name: Join as Additional Control Plane Node
      block:
        - name: Join the Kubernetes cluster as control plane node
          command: "{{ CP_JOIN_DATA }}"
          args:
            creates: /etc/kubernetes/admin.conf
          register: cp_join
          changed_when: true
          failed_when: cp_join.rc != 0
          until: cp_join is succeeded
          retries: 5
          delay: 30

        - name: Wait for node to be registered
          command: kubectl get node {{ ansible_hostname }}
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: node_registered
          changed_when: false
          until: node_registered.rc == 0
          retries: 30
          delay: 10

        - name: Remove taint from this control plane node
          command: kubectl taint nodes {{ ansible_hostname }} node-role.kubernetes.io/control-plane- --overwrite
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: remove_taint
          changed_when: remove_taint.rc == 0
          failed_when: false

        - name: Create .kube directory
          file:
            path: /root/.kube
            state: directory
            mode: "0755"

        - name: Copy kubeconfig to .kube/config
          copy:
            src: /etc/kubernetes/admin.conf
            dest: /root/.kube/config
            remote_src: true
            mode: "0600"
      when: CP_JOIN_DATA is defined and CP_JOIN_DATA | trim | length > 0

    - name: Reset Worker Node if needed
      block:
        - name: Check if kubelet.conf exists
          stat:
            path: /etc/kubernetes/kubelet.conf
          register: kubelet_conf

        - name: Check if node can reach API server
          command: kubectl get nodes
          environment:
            KUBECONFIG: /etc/kubernetes/kubelet.conf
          register: kubectl_check
          changed_when: false
          failed_when: false
          when: kubelet_conf.stat.exists

        - name: Reset Kubernetes if node cannot reach API server
          command: kubeadm reset --force
          register: kubeadm_reset
          changed_when: true
          failed_when: false
          when: kubelet_conf.stat.exists and kubectl_check.rc != 0
      when: WORKER_DATA is defined and WORKER_DATA | trim | length > 0

    - name: Initialize Kubernetes Worker Node
      block:
        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Join the Kubernetes cluster as worker node
          command: "{{ WORKER_DATA }}"
          args:
            creates: /etc/kubernetes/kubelet.conf
          register: worker_join
          changed_when: true
          failed_when: worker_join.rc != 0
          until: worker_join is succeeded
          retries: 5
          delay: 30
      when: WORKER_DATA is defined and WORKER_DATA | trim | length > 0
